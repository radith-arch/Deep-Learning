{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment17_DailyMinTemp_Radit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtoYJDRmWmsZ"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from datetime import datetime\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJln35XHv_2D",
        "outputId": "11819bbb-f3a6-46b7-8d17-0c97f7d1768b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgMJ81wTXRWd"
      },
      "source": [
        "# Datetime parser\n",
        "\n",
        "def parser(x):\n",
        "\treturn datetime.strptime(x, '%Y-%m-%d')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK8TCmqfXjn6",
        "outputId": "a255d044-31bc-4791-cf99-91f264101c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Load dataset\n",
        "\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Datasets/daily-min-temperatures.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
        "\n",
        "dataset.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "1981-01-01    20.7\n",
              "1981-01-02    17.9\n",
              "1981-01-03    18.8\n",
              "1981-01-04    14.6\n",
              "1981-01-05    15.8\n",
              "Name: Temp, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZTV9ywJX557",
        "outputId": "6f76dd70-acdf-4b45-8ce9-6ffc6702f668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Plot dataset\n",
        "\n",
        "dataset.plot()\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77SAQm5zbM2y"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gMZNZ4jbq9f"
      },
      "source": [
        "Processing Time-Series Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5SY8dU4b5rY"
      },
      "source": [
        "# frame a sequence as a supervised learning problem\n",
        "def timeseries_to_supervised(data, lag=1):\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
        "\tcolumns.append(df)\n",
        "\tdf = pd.concat(columns, axis=1)\n",
        "\treturn df\n",
        "\n",
        "# create a differenced series\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset)):\n",
        "\t\tvalue = dataset[i] - dataset[i - interval]\n",
        "\t\tdiff.append(value)\n",
        "\treturn pd.Series(diff)\n",
        "\n",
        "# #invert differenced value\n",
        "# def inverse_difference(history, yhat, interval=1):\n",
        "#   return yhat + history[-interval]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHira6KwdDXD"
      },
      "source": [
        "# # scale train dan test data to [-1, 1]\n",
        "# def scale(train, test):\n",
        "#   # fit scaler\n",
        "#   scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "#   scaler = scaler.fit(train)\n",
        "#   #transform train\n",
        "#   train = train.reshape(train.shape[0], train.shape[1])\n",
        "#   train_scaled = scaler.transform(train)\n",
        "#   #transform test\n",
        "#   test = test.reshape(test.shape[0], test.shape[1])\n",
        "#   test_scaled = scaler.transform(test)\n",
        "#   return scaler, train_scaled, test_scaled\n",
        "\n",
        "# # inverse scaling for a forecasted value\n",
        "# def invert_scale(scaler, X, yhat):\n",
        "#   new_row = [x for x in X] + [yhat]\n",
        "#   array = np.array(new_row)\n",
        "#   array = array.reshape(1, len(array))\n",
        "#   inverted = scaler.inverse_transform(array)\n",
        "#   return inverted[0, -1]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyW_8i_0ekfL",
        "outputId": "e99f3e7f-0cce-493e-acea-ae942b3fcd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "lag = 1\n",
        "\n",
        "# transform data to be stationary\n",
        "raw_values = dataset.values\n",
        "raw_values\n",
        "diff_values = difference(raw_values, 1)\n",
        "diff_values\n",
        "\n",
        "# transform data to be supervised learning\n",
        "supervised = timeseries_to_supervised(diff_values, lag)\n",
        "supervised\n",
        "supervised_values = supervised.values[lag:, :]\n",
        "supervised_values"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.8,  0.9],\n",
              "       [ 0.9, -4.2],\n",
              "       [-4.2,  1.2],\n",
              "       ...,\n",
              "       [-0.4, -0.1],\n",
              "       [-0.1,  2.2],\n",
              "       [ 2.2, -2.7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EswI5oShfdqa"
      },
      "source": [
        "split_percentage = 0.75\n",
        "\n",
        "train_size = int(split_percentage * len(supervised_values))\n",
        "\n",
        "train, test = supervised_values[0:train_size], supervised_values[train_size:len(supervised_values)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1I8eRpUie5A"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "scaler = scaler.fit(train)\n",
        "\n",
        "train_scaled = scaler.transform(train)\n",
        "test_scaled = scaler.transform(test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USVdrH6hjxVB",
        "outputId": "440cb3e8-65ca-4363-add3-f6f830b4eb73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_scaled"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.11607143,  0.21428571],\n",
              "       [ 0.21428571, -0.24107143],\n",
              "       [-0.24107143,  0.24107143],\n",
              "       ...,\n",
              "       [-0.16071429,  0.375     ],\n",
              "       [ 0.375     ,  0.125     ],\n",
              "       [ 0.125     , -0.16071429]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24WRvyKIj72N"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWJPd7ODkA61",
        "outputId": "b0674cb0-00ac-4d95-9c0a-38f3d1249a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "feature_train, label_train = train_scaled[:, 0:-1], train_scaled[:, -1]\n",
        "feature_test, label_test = test_scaled[:, 0:-1], test_scaled[:, -1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history_baseline = model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0585\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.0566\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.0559\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0614 - val_loss: 0.0556\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0554\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.0553\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.0552\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0550\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0549\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0548\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0547\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0546\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0545\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0543\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0544\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0542\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0542\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0542\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0542\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0540\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0543\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0542\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0540\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0541\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_cUFoTYlF-Y",
        "outputId": "41ede514-f2ec-469b-fedf-458f6656bf0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss = model.evaluate(feature_test, verbose=2)\n",
        "\n",
        "print(\"Test loss:\", loss)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29/29 - 0s - loss: 0.0000e+00\n",
            "Test loss: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB5O5yp1liwG"
      },
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSZeiphAl5yJ",
        "outputId": "74eb19b0-41d7-4011-b69f-3b97616ca894",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "history_baseline_dataframe = pd.DataFrame(history_baseline.history)\n",
        "history_baseline_dataframe['epoch'] = history_baseline.epoch\n",
        "history_baseline_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>0.058747</td>\n",
              "      <td>0.053976</td>\n",
              "      <td>742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>0.058747</td>\n",
              "      <td>0.053976</td>\n",
              "      <td>236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0.058750</td>\n",
              "      <td>0.053976</td>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>854</th>\n",
              "      <td>0.058794</td>\n",
              "      <td>0.053976</td>\n",
              "      <td>854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>711</th>\n",
              "      <td>0.058831</td>\n",
              "      <td>0.053976</td>\n",
              "      <td>711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.061116</td>\n",
              "      <td>0.055420</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.061417</td>\n",
              "      <td>0.055568</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.062088</td>\n",
              "      <td>0.055896</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.063550</td>\n",
              "      <td>0.056556</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.068116</td>\n",
              "      <td>0.058461</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "742  0.058747  0.053976    742\n",
              "236  0.058747  0.053976    236\n",
              "497  0.058750  0.053976    497\n",
              "854  0.058794  0.053976    854\n",
              "711  0.058831  0.053976    711\n",
              "..        ...       ...    ...\n",
              "4    0.061116  0.055420      4\n",
              "3    0.061417  0.055568      3\n",
              "2    0.062088  0.055896      2\n",
              "1    0.063550  0.056556      1\n",
              "0    0.068116  0.058461      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0YAj0uzmPpL",
        "outputId": "a0ffa677-1138-445b-a9cc-a16865926b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history_baseline)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORIxt2dXmUxU"
      },
      "source": [
        "## Deeper Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPVHIB9LmWeb",
        "outputId": "6cea6a3c-30d6-46fa-9f80-59d0b4b4bb48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "deeper_model = Sequential()\n",
        "deeper_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "deeper_model.add(Dense(5, activation='relu'))\n",
        "deeper_model.add(Dense(1))\n",
        "deeper_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "deeper_model_history = deeper_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0564\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0548\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0547\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0546\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0545\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0545\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0545\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0545\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0545\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0543\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0543\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0543\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0543\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0543\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0543\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0543\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0543\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0543\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0542\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0542\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0542\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0542\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0542\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0542\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0543\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0544\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0546\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0543\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0543\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0538\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0543\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0544\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0545\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0543\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixplKEM6nKH4",
        "outputId": "90fa7d32-0a13-496d-891a-785b4ea1ee4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "deeper_model_dataframe = pd.DataFrame(deeper_model_history.history)\n",
        "deeper_model_dataframe['epoch'] = deeper_model_history\n",
        "deeper_model_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>0.058112</td>\n",
              "      <td>0.053839</td>\n",
              "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0.058154</td>\n",
              "      <td>0.053841</td>\n",
              "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>0.058180</td>\n",
              "      <td>0.053843</td>\n",
              "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>0.058145</td>\n",
              "      <td>0.053846</td>\n",
              "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>0.058153</td>\n",
              "      <td>0.053847</td>\n",
              "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.058972</td>\n",
              "      <td>0.054620</td>\n",
              "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>0.057975</td>\n",
              "      <td>0.054635</td>\n",
              "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.059063</td>\n",
              "      <td>0.054712</td>\n",
              "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.059567</td>\n",
              "      <td>0.054824</td>\n",
              "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.075979</td>\n",
              "      <td>0.056431</td>\n",
              "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss                                              epoch\n",
              "692  0.058112  0.053839  <tensorflow.python.keras.callbacks.History obj...\n",
              "999  0.058154  0.053841  <tensorflow.python.keras.callbacks.History obj...\n",
              "362  0.058180  0.053843  <tensorflow.python.keras.callbacks.History obj...\n",
              "361  0.058145  0.053846  <tensorflow.python.keras.callbacks.History obj...\n",
              "749  0.058153  0.053847  <tensorflow.python.keras.callbacks.History obj...\n",
              "..        ...       ...                                                ...\n",
              "3    0.058972  0.054620  <tensorflow.python.keras.callbacks.History obj...\n",
              "330  0.057975  0.054635  <tensorflow.python.keras.callbacks.History obj...\n",
              "2    0.059063  0.054712  <tensorflow.python.keras.callbacks.History obj...\n",
              "1    0.059567  0.054824  <tensorflow.python.keras.callbacks.History obj...\n",
              "0    0.075979  0.056431  <tensorflow.python.keras.callbacks.History obj...\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwXcQ2lqnhkD",
        "outputId": "c687ad6a-be65-428f-d330-3201355945cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(deeper_model_history)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5wJE60wnlh8"
      },
      "source": [
        "## Wider Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpemXRFBnoci",
        "outputId": "168bcb52-5160-4621-d6ba-780fcd23ccd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 50\n",
        "epoch = 1000\n",
        "batch_size =32\n",
        "\n",
        "wider_model = Sequential()\n",
        "wider_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "wider_model.add(Dense(1))\n",
        "wider_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "wider_model_history = wider_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0624 - val_loss: 0.0541\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0542\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0540\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0537\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0555\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0544\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0543\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0538\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0545\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0547\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0543\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0546\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0543\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0545\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0545\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0545\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0543\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0545\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0546\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0545\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0545\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0545\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0545\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0545\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0544\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0538\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0545\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0545\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0546\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0546\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0545\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0545\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0545\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0545\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbUzFuG1oZH5",
        "outputId": "487b47d7-250d-49a7-ee48-60ffad601493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "wider_model_dataframe = pd.DataFrame(wider_model_history.history)\n",
        "wider_model_dataframe['epoch'] = wider_model_history.epoch\n",
        "wider_model_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.058113</td>\n",
              "      <td>0.053716</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>0.057850</td>\n",
              "      <td>0.053769</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>0.058101</td>\n",
              "      <td>0.053770</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.057865</td>\n",
              "      <td>0.053774</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>0.057906</td>\n",
              "      <td>0.053775</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783</th>\n",
              "      <td>0.057417</td>\n",
              "      <td>0.054584</td>\n",
              "      <td>783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0.057781</td>\n",
              "      <td>0.054608</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>0.057311</td>\n",
              "      <td>0.054612</td>\n",
              "      <td>883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.057842</td>\n",
              "      <td>0.054689</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.057979</td>\n",
              "      <td>0.055500</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "12   0.058113  0.053716     12\n",
              "65   0.057850  0.053769     65\n",
              "60   0.058101  0.053770     60\n",
              "20   0.057865  0.053774     20\n",
              "68   0.057906  0.053775     68\n",
              "..        ...       ...    ...\n",
              "783  0.057417  0.054584    783\n",
              "100  0.057781  0.054608    100\n",
              "883  0.057311  0.054612    883\n",
              "56   0.057842  0.054689     56\n",
              "14   0.057979  0.055500     14\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRd6yfKZosHk",
        "outputId": "2eb912eb-ab6d-458b-ee6d-40253a50a335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(wider_model_history)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag1U-_BVowGA"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pP4u8yToyTR",
        "outputId": "b3ec199e-1df9-46d1-e2e3-7cc803e2d54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "feature_train_reshaped = np.reshape(feature_train, (feature_train.shape[0], 1, feature_train.shape[1]))\n",
        "feature_test_reshaped = np.reshape(feature_test, (feature_test.shape[0], 1, feature_test.shape[1]))\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, activation='relu', input_dim=feature_train.shape[1])) # 50 LSTM Block\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "lstm_model_history = lstm_model.fit(feature_train_reshaped, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test_reshaped, label_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0645 - val_loss: 0.0545\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0590 - val_loss: 0.0541\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0540\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0540\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0539\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0542\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB2ga_s2qXi8",
        "outputId": "1319d1fb-a18a-4a62-e391-f2006bedc47f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "lstm_history_dataframe = pd.DataFrame(lstm_model_history.history)\n",
        "lstm_history_dataframe['epoch'] = lstm_model_history.epoch\n",
        "lstm_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>0.057823</td>\n",
              "      <td>0.053762</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.057864</td>\n",
              "      <td>0.053767</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>0.057833</td>\n",
              "      <td>0.053767</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0.057899</td>\n",
              "      <td>0.053768</td>\n",
              "      <td>261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>0.057749</td>\n",
              "      <td>0.053768</td>\n",
              "      <td>763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.058153</td>\n",
              "      <td>0.054170</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>0.058104</td>\n",
              "      <td>0.054178</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.058496</td>\n",
              "      <td>0.054190</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.058242</td>\n",
              "      <td>0.054217</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.064549</td>\n",
              "      <td>0.054512</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "191  0.057823  0.053762    191\n",
              "195  0.057864  0.053767    195\n",
              "213  0.057833  0.053767    213\n",
              "261  0.057899  0.053768    261\n",
              "763  0.057749  0.053768    763\n",
              "..        ...       ...    ...\n",
              "30   0.058153  0.054170     30\n",
              "74   0.058104  0.054178     74\n",
              "7    0.058496  0.054190      7\n",
              "20   0.058242  0.054217     20\n",
              "0    0.064549  0.054512      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO3GWLkxqqBQ",
        "outputId": "a3961269-0dc9-4449-8799-c42290a554ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(lstm_model_history)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSEDS23N33Ej"
      },
      "source": [
        "# Kesimpulan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJqe6ibC38Z0"
      },
      "source": [
        "Dari data di atas, didapatkan hasil:\n",
        "\n",
        "*   Baseline Model \t\n",
        "loss 0.058747   \n",
        "val_loss 0.053976    \n",
        "epoch 742\n",
        "\n",
        "*   Deeper Model\n",
        "loss 0.058112\t\t    \n",
        "val_loss 0.053839\t\t    \n",
        "epoch 692\n",
        "     \n",
        "*   Wider Model    \n",
        "loss 0.058113\t   \n",
        "val_loss 0.053716     \n",
        "epoch 12\n",
        "\n",
        "*   LSTM           \n",
        "loss 0.057823\t   \n",
        "val_loss 0.053762\t    \n",
        "epoch 191\n",
        "\n",
        "Nilai validation loss terkecil ada pada Wider Model epoch 12.Perbedaan hasil validation loss dan epoch setiap model cukup besar. Hal ini berarti dari awal model yang diberikan, neurons yang dikasih terlalu kecil. Pada deeper model sendiri validation loss didapatkan pada epoch ke 692, meningkat dari hasil baseline model sehingga memungkinkan ketika dilakukan penambahan kedalaman layer dan diberikan neuron yang lebih lebar akan mendapatkan nilai epoch jauh lebih kecil lagi. Pada model LSTM sendiri hasilnya tidak jauh berbeda dengan wider model pada nilai validation loss, sedangkan untuk nilai loss training lebih baik pada LSTM. Jadi mungkin dengan memakai LSTM mungkin nilai loss dan validation loss yang dihasilkan bisa lebih kecil, namun pada dataset ini memakai wider model sudah cukup untuk menghasilkan validation loss terbaik. \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}